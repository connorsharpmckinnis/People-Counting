{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67b05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from ultralytics.utils.plotting import Annotator, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5d77988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11n.pt\")\n",
    "image_path = \"people.jpg\"\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bc041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionResult:\n",
    "    def __init__(self, boxes, scores, class_ids, meta=None):\n",
    "        self.boxes = boxes\n",
    "        self.scores = scores\n",
    "        self.class_ids = class_ids\n",
    "        self.meta = meta or {}\n",
    "\n",
    "class DetectionEngine:\n",
    "    def __init__(self, model_path, confidence_threshold=0.3, device=\"cpu\", use_slicing=False):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.device = device\n",
    "    \n",
    "    def detect(self, image, classes_to_detect=None):\n",
    "        results = self.model.predict(\n",
    "            image,\n",
    "            conf=self.confidence_threshold,\n",
    "            device=self.device\n",
    "        )[0]\n",
    "\n",
    "        boxes, scores, class_ids = [], [], []\n",
    "\n",
    "        for box, score, cls in zip(results.boxes.xyxy, results.boxes.conf, results.boxes.cls):\n",
    "            class_id = int(cls)\n",
    "            if classes_to_detect and class_id not in classes_to_detect:\n",
    "                continue\n",
    "\n",
    "            boxes.append(box.tolist())     # xyxy format\n",
    "            scores.append(float(score))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "        boxes = np.array(boxes, dtype=float)\n",
    "        scores = np.array(scores, dtype=float)\n",
    "        class_ids = np.array(class_ids, dtype=int)\n",
    "\n",
    "        meta = {\n",
    "            \"num_detections\": len(boxes),\n",
    "            \"model_name\": self.model.model,\n",
    "            \"device\": self.device,\n",
    "        }\n",
    "\n",
    "        return DetectionResult(boxes, scores, class_ids, meta)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54075eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotationEngine:\n",
    "    def __init__(self):\n",
    "        pass  # No config needed yet, could add font/line width overrides later\n",
    "\n",
    "    def annotate(self, image, detection_result):\n",
    "        annotated_img = image.copy()\n",
    "        annotator = Annotator(annotated_img, line_width=2)\n",
    "\n",
    "        boxes = detection_result.boxes\n",
    "        scores = detection_result.scores\n",
    "        class_ids = detection_result.class_ids\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            bbox = boxes[i]\n",
    "            cls_id = class_ids[i]\n",
    "            conf = scores[i]\n",
    "            label = f\"{cls_id} {conf:.2f}\"\n",
    "\n",
    "            annotator.box_label(bbox, label, color=colors(cls_id))\n",
    "\n",
    "        return annotator.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 7 persons, 1 chair, 49.2ms\n",
      "Speed: 2.7ms preprocess, 49.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "[[9.09118652e-01 5.69069641e+02 1.17686142e+02 6.83000000e+02]\n",
      " [2.98549652e+02 4.68950989e+02 3.91812561e+02 6.65558228e+02]\n",
      " [8.24189819e+02 6.08791626e+02 9.23080444e+02 6.77780273e+02]\n",
      " [6.60499023e+02 5.22961243e+02 8.07387512e+02 6.79005981e+02]\n",
      " [3.77099854e+02 5.24484009e+02 4.58947327e+02 6.74534180e+02]\n",
      " [4.18239166e+02 4.93053894e+02 5.03974701e+02 5.91818359e+02]\n",
      " [7.01522827e+02 5.22608887e+02 8.08141418e+02 6.71710815e+02]\n",
      " [5.83080322e+02 4.57838928e+02 6.53853943e+02 5.49649780e+02]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    engine = DetectionEngine(\"yolo11n.pt\")\n",
    "    result = engine.detect(image)\n",
    "    \n",
    "    annotator = AnnotationEngine()\n",
    "    annotated = annotator.annotate(image, result)\n",
    "    \n",
    "    cv2.imshow(\"Annotated\", annotated)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "court-ocupancy (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
